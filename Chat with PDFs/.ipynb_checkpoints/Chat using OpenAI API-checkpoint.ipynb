{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c65372e2-17e4-4f25-ad14-c7225f89e0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251907"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6681b7-d81d-4f23-9508-0852ae81ae23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7da14a5e-ef43-4e5e-9ff5-9aeee2657620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4946e85-abe9-43e3-8ce6-75be57a91cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/homebrew/opt/python@3.9/bin/python3.9'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f404d94-dd34-4f10-9e83-f132c74129b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = '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'\n",
    "\n",
    "import pdf2image\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "image = pdf2image.convert_from_path('bcg-2022-annual-sustainability-report-apr-2023.pdf')\n",
    "for pagenumber, page in enumerate(image):\n",
    "    detected_text = pytesseract.image_to_string(page)\n",
    "    \n",
    "system_msg = 'You are an electorics board expert'\n",
    "\n",
    "query = '''\n",
    "How do I connect my Arduino UNO R3 to my computer?\n",
    "'''\n",
    "\n",
    "user_msg = detected_text + '\\n\\n' + query\n",
    "\n",
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                        messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                                         {\"role\": \"user\", \"content\": user_msg}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc1dfb47-ef56-4a75-a2a4-1423a00d1583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c4d72-ab03-4b06-afdb-5a3b37aa5985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64159d5a-28b5-43a0-8220-c995799a42ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = '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'\n",
    "\n",
    "import pdf2image\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "image = pdf2image.convert_from_path('future of finance.pdf')\n",
    "for pagenumber, page in enumerate(image):\n",
    "    detected_text = pytesseract.image_to_string(page)\n",
    "    \n",
    "system_msg = 'You are an accounts payable expert.'\n",
    "\n",
    "query = '''\n",
    "Classify this document and return one of these two document types as response - [Invoices, Receipts]\n",
    "Return only the document type in the response.\n",
    "\n",
    "Document Type = \n",
    "'''\n",
    "\n",
    "user_msg = detected_text + '\\n\\n' + query\n",
    "\n",
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                        messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                                         {\"role\": \"user\", \"content\": user_msg}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40997c43-c7bb-40a8-8f0f-2ca0615b86d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a414e500-cefc-498a-8717-2a088f2a1e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48f81593-9c3a-4289-95af-89bcb3337e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoices\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a79e0693-c00b-404a-ad7b-fc4d23862a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_textort json\n",
    "invoice_json = json.loads(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "facbe84c-26dd-43ad-b046-e780f41f4c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"invoice_date\": \"May 24th, 2024\",\n",
      "    \"invoice_number\": \"12345\",\n",
      "    \"seller_name\": \"Anvil Co\",\n",
      "    \"seller_address\": \"123 Main Street, San Francisco CA, 94103\",\n",
      "    \"total_amount\": \"$105.00\",\n",
      "    \"line_items\": [\n",
      "        {\n",
      "            \"quantity\": 2,\n",
      "            \"description\": \"Blue large widgets\",\n",
      "            \"price\": \"$15.00\"\n",
      "        },\n",
      "        {\n",
      "            \"quantity\": 4,\n",
      "            \"description\": \"Green medium widgets\",\n",
      "            \"price\": \"$10.00\"\n",
      "        },\n",
      "        {\n",
      "            \"quantity\": 5,\n",
      "            \"description\": \"Red small widgets with logo\",\n",
      "            \"price\": \"$7.00\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pretty_json = json.dumps(invoice_json, indent=4)\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f03846c-25b1-46e8-a166-2e6e58412f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-13.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-12.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-10.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-11.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-15.pdf\n",
      "File moved to invoices and receipts/Receipts/00b20a0a-4e3c-46e6-b07c-830d79ca6665-10 copy.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-14.pdf\n",
      "File moved to invoices and receipts/Receipts/00b20a0a-4e3c-46e6-b07c-830d79ca6665-16.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-17.pdf\n",
      "File moved to invoices and receipts/Receipts/00b20a0a-4e3c-46e6-b07c-830d79ca6665-9.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-8.pdf\n",
      "File moved to invoices and receipts/Receipts/00b20a0a-4e3c-46e6-b07c-830d79ca6665-3 copy 2.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-1.pdf\n",
      "File moved to invoices and receipts/Receipts/00b20a0a-4e3c-46e6-b07c-830d79ca6665-3.pdf\n",
      "File moved to invoices and receipts/Receipts/00b20a0a-4e3c-46e6-b07c-830d79ca6665-2.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-6.pdf\n",
      "File moved to invoices and receipts/Receipts/00b20a0a-4e3c-46e6-b07c-830d79ca6665-10 copy 2.pdf\n",
      "File moved to invoices and receipts/Receipts/00b20a0a-4e3c-46e6-b07c-830d79ca6665-3 copy.pdf\n",
      "File moved to invoices and receipts/Receipts/00b20a0a-4e3c-46e6-b07c-830d79ca6665-4.pdf\n",
      "File moved to invoices and receipts/Invoices/004924c4-1a29-4979-8c1b-321141ca4811.pdf\n",
      "File moved to invoices and receipts/Invoices/00b20a0a-4e3c-46e6-b07c-830d79ca6665-18.pdf\n"
     ]
    }
   ],
   "source": [
    "list_of_files = list_files_only('invoices and receipts/')\n",
    "for doc in list_of_files:\n",
    "    current_path = 'invoices and receipts/' + doc\n",
    "    doc_type = classify(current_path)\n",
    "    new_path = 'invoices and receipts/' + doc_type\n",
    "    move_file(current_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d9118-50ee-42f8-9718-353f74114baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71f2a87f-4a4f-49ef-b112-100a2b7373a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def list_files_only(directory_path):\n",
    "    if os.path.isdir(directory_path):\n",
    "        file_list = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "        file_list = [file for file in file_list if \".pdf\" in file]\n",
    "        return file_list\n",
    "    else:\n",
    "        return f\"{directory_path} is not a directory\"\n",
    "\n",
    "def classify(file_name):\n",
    "    \n",
    "    image = pdf2image.convert_from_path(file_name)\n",
    "    for pagenumber, page in enumerate(image):\n",
    "        detected_text = pytesseract.image_to_string(page)\n",
    "    \n",
    "    system_msg = 'You are an accounts payable expert.'\n",
    "\n",
    "    query = '''\n",
    "    Classify this document and return one of these two document types as response - [Invoices, Receipts]\n",
    "    Return only the document type in the response.\n",
    "\n",
    "    Document Type = \n",
    "    '''\n",
    "\n",
    "    user_msg = detected_text + '\\n\\n' + query\n",
    "\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                            messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                                             {\"role\": \"user\", \"content\": user_msg}])\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def move_file(current_path, new_folder):\n",
    "    if os.path.isfile(current_path) and os.path.isdir(new_folder):\n",
    "        file_name = os.path.basename(current_path)\n",
    "        new_path = os.path.join(new_folder, file_name)\n",
    "        shutil.move(current_path, new_path)\n",
    "        print(f'File moved to {new_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90a0e29b-3cd8-4f71-bbdc-af6295ed59f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251907\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "pdf_file_obj = open('bcg-2022-annual-sustainability-report-apr-2023.pdf', 'rb')\n",
    "pdf_reader = PyPDF2.PdfFileReader(pdf_file_obj)\n",
    "num_pages = pdf_reader.numPages\n",
    "detected_text = ''\n",
    "\n",
    "for page_num in range(num_pages):\n",
    "    page_obj = pdf_reader.getPage(page_num)\n",
    "    detected_text += page_obj.extractText() + '\\n\\n'\n",
    "\n",
    "pdf_file_obj.close()\n",
    "print(len(detected_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f40a85-43c6-4af1-a74b-aa29dfdd14fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f008f37a-3de3-4bc3-aa2a-caf5dbf49aea",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 54696 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124msummarize this PDF in 500 words.\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      7\u001b[0m user_msg \u001b[38;5;241m=\u001b[39m detected_text \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m query\n\u001b[0;32m----> 9\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_msg\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_msg\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 54696 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "system_msg = ''\n",
    "\n",
    "query = '''\n",
    "summarize this PDF in 500 words.\n",
    "'''\n",
    "\n",
    "user_msg = detected_text + '\\n\\n' + query\n",
    "\n",
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                        messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                                         {\"role\": \"user\", \"content\": user_msg}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9a5c2f3-eb97-4039-960d-a5e918bd9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "baedc74a-1a09-4400-8760-a017c300da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0efafc7d-5b6a-4276-b4bd-b9e388d08367",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"bcg-2022-annual-sustainability-report-apr-2023.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "377c7529-992e-4b1b-8975-76af45df934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.create_documents([detected_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4fea387f-a5c9-4502-b8cb-a8c9e026429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'index_store'\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "faiss.write_index(vector_index, directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
